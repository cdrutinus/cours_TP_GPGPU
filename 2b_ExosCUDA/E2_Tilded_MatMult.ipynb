{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E2_Tilded_MatMult.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH4EnLbWoNzv"
      },
      "source": [
        "\"\"\"\n",
        "Code adapted from: https://shephexd.github.io/development/2017/02/19/pycuda.html\n",
        "\n",
        "If using google colab:\n",
        "* Click on Runtime (excecution) and select Change runtime type (modifier le type d'excecution).\n",
        "  Then select GPU in Hardware Acceleration (accélérateur matériel)\n",
        "* Start your session by installing pycuda with the command:\n",
        "\n",
        "  -> !pip install pycuda\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Multiples two square matrices together using multiple blocks and shared memory.\n",
        "Each thread block is assigned a \"tile\" of the resulting matrix and is responsible\n",
        "for generating the elements in that tile.  Each thread in a block computes one element\n",
        "of the tile.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZjJwtlnoYl9",
        "outputId": "f3c15aed-82b2-4217-a135-15c13723c02b"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 5.6MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=621085 sha256=689f0e911a05b8f0e3b7db1efaa752b24241e796d77ad194182142851dffa850\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=8d9dda432e4ba69040e565200b6b75fc945c45a78bea1c238a15c8a0398ea8b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pbtgx6SoIi-"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMGAM84Fogaf"
      },
      "source": [
        "# -- initialize the device\n",
        "import pycuda.autoinit"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMn3LLA9omFF"
      },
      "source": [
        "# define the (square) matrix size\n",
        "#  note that we'll only use *one* block of threads here\n",
        "#  as a consequence this number (squared) can't exceed max_threads\n",
        "# -> use MyDevice.get_attributes() to get this information\n",
        "MATRIX_SIZE = 1024\n",
        "\n",
        "def matmul(a_gpu,b_gpu,MATRIX_SIZE=MATRIX_SIZE):\n",
        "    kernel_code_template = \"\"\"\n",
        "    __global__ void MatrixMulKernel(float *A, float *B, float *C)\n",
        "    {\n",
        "\n",
        "      const uint wA = %(MATRIX_SIZE)s;\n",
        "      const uint wB = %(MATRIX_SIZE)s;\n",
        "\n",
        "      // Block index\n",
        "      const uint bx = blockIdx.x;\n",
        "      const uint by = blockIdx.y;\n",
        "\n",
        "      // Thread index\n",
        "      const uint tx = threadIdx.x;\n",
        "      const uint ty = threadIdx.y;\n",
        "\n",
        "      // Index of the first sub-matrix of A processed by the block\n",
        "      const uint aBegin = wA * %(BLOCK_SIZE)s * by;\n",
        "      // Index of the last sub-matrix of A processed by the block\n",
        "      const uint aEnd = aBegin + wA - 1;\n",
        "      // Step size used to iterate through the sub-matrices of A\n",
        "      const uint aStep = %(BLOCK_SIZE)s;\n",
        "\n",
        "      // Index of the first sub-matrix of B processed by the block\n",
        "      const uint bBegin = %(BLOCK_SIZE)s * bx;\n",
        "      // Step size used to iterate through the sub-matrices of B\n",
        "      const uint bStep = %(BLOCK_SIZE)s * wB;\n",
        "\n",
        "      // The element of the block sub-matrix that is computed\n",
        "      // by the thread\n",
        "      float Csub = 0;\n",
        "      // Loop over all the sub-matrices of A and B required to\n",
        "      // compute the block sub-matrix\n",
        "      for (int a = aBegin, b = bBegin;\n",
        "           a <= aEnd;\n",
        "           a += aStep, b += bStep)\n",
        "        {\n",
        "          // Shared memory for the sub-matrix of A\n",
        "          __shared__ float As[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "          // Shared memory for the sub-matrix of B\n",
        "          __shared__ float Bs[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "\n",
        "          // Load the matrices from global memory to shared memory\n",
        "          // each thread loads one element of each matrix\n",
        "          As[ty][tx] = A[a + wA * ty + tx];\n",
        "          Bs[ty][tx] = B[b + wB * ty + tx];\n",
        "          // Synchronize to make sure the matrices are loaded\n",
        "          __syncthreads();\n",
        "\n",
        "          // Multiply the two matrices together;\n",
        "          // each thread computes one element\n",
        "          // of the block sub-matrix\n",
        "          for (int k = 0; k < %(BLOCK_SIZE)s; ++k)\n",
        "            Csub += As[ty][k] * Bs[k][tx];\n",
        "\n",
        "          // Synchronize to make sure that the preceding\n",
        "          // computation is done before loading two new\n",
        "          // sub-matrices of A and B in the next iteration\n",
        "          __syncthreads();\n",
        "        }\n",
        "\n",
        "      // Write the block sub-matrix to global memory;\n",
        "      // each thread writes one element\n",
        "      const uint c = wB * %(BLOCK_SIZE)s * by + %(BLOCK_SIZE)s * bx;\n",
        "      C[c + wB * ty + tx] = Csub;\n",
        "    }\n",
        "    \"\"\"\n",
        "        # define size of blocks and tiles sub-matrix\n",
        "    # (we assume that the block size is same as tile size)\n",
        "    TILE_SIZE = 32\n",
        "    BLOCK_SIZE = TILE_SIZE\n",
        "\n",
        "    # get the kernel code from the template\n",
        "    # by specifying the constants MATRIX_SIZE and BLOCK_SIZE\n",
        "    kernel_code = kernel_code_template % {\n",
        "        'MATRIX_SIZE': MATRIX_SIZE,\n",
        "        'BLOCK_SIZE': BLOCK_SIZE,\n",
        "        }\n",
        "\n",
        "    # compile the kernel code\n",
        "    mod = compiler.SourceModule(kernel_code)\n",
        "\n",
        "    # create empty gpu array for the result (C = A * B)\n",
        "    c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "    # get the kernel function from the compiled module\n",
        "    matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "    # call the kernel on the card\n",
        "    time_start=time.time()\n",
        "    matrixmul(\n",
        "        # inputs\n",
        "        a_gpu, b_gpu,\n",
        "        # output\n",
        "        c_gpu,\n",
        "        # grid of multiple blocks\n",
        "        grid = (MATRIX_SIZE // TILE_SIZE, MATRIX_SIZE // TILE_SIZE),\n",
        "        # block of multiple threads\n",
        "        block = (TILE_SIZE, TILE_SIZE, 1),\n",
        "        )\n",
        "    time_end=time.time()\n",
        "    print('enlapsed time (GPU):',time_end-time_start,' seconds')\n",
        "\n",
        "    return c_gpu, time_end-time_start"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa7FHK5ioooS"
      },
      "source": [
        "# create two random square matrices\n",
        "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2gmDQrOo-G4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1fab25-a438-4951-fa21-be7e21149c3d"
      },
      "source": [
        "# compute reference on the CPU to verify GPU computation\n",
        "time_start=time.time()\n",
        "c_cpu = np.dot(a_cpu, b_cpu)\n",
        "time_end=time.time()\n",
        "timeCPU = time_end-time_start\n",
        "print('enlapsed time (CPU):',timeCPU,' seconds')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enlapsed time (CPU): 0.0404362678527832  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcq4CMaL15ci",
        "outputId": "4c2208e3-1553-46fe-b55f-b2d75de9d3cb"
      },
      "source": [
        "# transfer host (CPU) memory to device (GPU) memory\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "# calculate the multiplication\n",
        "c_gpu, timeGPU = matmul(a_gpu,b_gpu)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enlapsed time (GPU): 0.0001423358917236328  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo3fQ3Y-2e0Y",
        "outputId": "2dc0ebfd-49ba-4829-dcd2-73300b7f5644"
      },
      "source": [
        "# print the results\n",
        "def display(verbose=False):\n",
        "\n",
        "  print(\"Taille matrices : \", MATRIX_SIZE)\n",
        "  #print Matrices\n",
        "  if verbose == True:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Matrix A (GPU):\")\n",
        "    print(a_gpu.get())\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Matrix B (GPU):\")\n",
        "    print(b_gpu.get())\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Matrix C (GPU):\")\n",
        "    print(c_gpu.get())\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "  #print difference\n",
        "  print(\"CPU-GPU difference:\")\n",
        "  norm = np.linalg.norm(c_cpu - c_gpu.get())\n",
        "  if norm != 0:\n",
        "    print(c_cpu - c_gpu.get())\n",
        "  print(\"Norme of the difference : \", norm)\n",
        "\n",
        "  #print difference time\n",
        "  print()\n",
        "  print(\"Rapport de temps CPU/GPU : \", round(timeCPU/timeGPU,3))\n",
        "\n",
        "display()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taille matrices :  1024\n",
            "CPU-GPU difference:\n",
            "[[ 0.0000000e+00 -1.1444092e-05 -1.0848045e-05 ...  6.6757202e-06\n",
            "  -7.6293945e-06  1.9848347e-05]\n",
            " [ 1.9073486e-06 -9.5367432e-06 -7.6293945e-06 ... -1.6689301e-06\n",
            "  -3.0517578e-05 -1.5258789e-05]\n",
            " [-2.4795532e-05 -3.0517578e-05 -7.6293945e-06 ... -1.9073486e-06\n",
            "   0.0000000e+00 -8.5830688e-06]\n",
            " ...\n",
            " [ 6.1035156e-05 -6.6757202e-06 -5.7220459e-06 ...  1.1444092e-05\n",
            "   1.1444092e-05  1.9073486e-06]\n",
            " [ 4.1961670e-05 -5.7220459e-06  9.2983246e-06 ...  1.5258789e-05\n",
            "   0.0000000e+00 -1.5258789e-05]\n",
            " [-1.9073486e-05  1.2874603e-05  3.8146973e-06 ... -9.5367432e-07\n",
            "  -1.5258789e-05 -6.1988831e-06]]\n",
            "Norme of the difference :  0.018887706\n",
            "\n",
            "Rapport de temps CPU/GPU :  284.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovD88mOL_VRC"
      },
      "source": [
        "#QUESTION 1: Comprenez bien chaque partie du code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxBSBLJDIAJl"
      },
      "source": [
        "Done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By0nWzTDAQOU"
      },
      "source": [
        "#QUESTION 2: Comparez les gain de temps de la multiplication en CPU a celle en GPU avec ceux de l'exercice precedent. Comment expliquez vous que la methode GPU soit largement competitive maintenant ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_wHI4euIWpv"
      },
      "source": [
        "Cette fois-ci, la taille de la matrice est plus importante, ce qui rend le gain de temps de la parallélisation plus net. De plus, on a séparé les Threads en blocs, ce qui a donc amélioré le rendement du processus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h8CZJ90_QCe"
      },
      "source": [
        "#QUESTION 3: Jouez avec la taille de la matrice et celle des tuiles (tile). Est-ce que le gain de temps en utilisant le GPU depend fortement de la taille de la matrice ? Est-ce que le choix de la taille des tuiles a une grande influence sur les gains de temps de calculs ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w82sILm1IsuB"
      },
      "source": [
        "La taille de la matrice fait varier le gain de temps en utilisant le GPU.\n",
        "La taille des tuiles n'a pas une grande influence sur les gains de temps de calculs."
      ]
    }
  ]
}