{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E1_basic_MatMult.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH4EnLbWoNzv"
      },
      "source": [
        "Code adapted from  https://shephexd.github.io/development/2017/02/19/pycuda.html\n",
        "\n",
        "If using google colab:\n",
        "* Click on Runtime (excecution) and select Change runtime type (modifier le type d'excecution).\n",
        "  Then select GPU in Hardware Acceleration (accélérateur matériel)\n",
        "* Start your session by installing pycuda with the command:\n",
        "\n",
        "  -> !pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZjJwtlnoYl9",
        "outputId": "512c62fa-becd-4357-e5b4-272e91cc66c3"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 9.1MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=621085 sha256=ca3286ca8dda7977dddd4bd47ed84023ce90caff2d7f7fb3c21630723be1608c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=093d7f11c0d41991632aad053c6c4fff000b062483f326ffbb3dc51f3eeb0d25\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pbtgx6SoIi-"
      },
      "source": [
        "import numpy as np\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "import time"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMGAM84Fogaf",
        "outputId": "c7e8e999-6e49-4488-8dd9-28489e63ae82"
      },
      "source": [
        "# -- initialize the device\n",
        "import pycuda.autoinit\n",
        "\n",
        "\n",
        "#get device information\n",
        "MyDevice=pycuda.driver.Device(0)\n",
        "MyDevice.get_attributes()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{pycuda._driver.device_attribute.MAX_THREADS_PER_BLOCK: 1024,\n",
              " pycuda._driver.device_attribute.MAX_BLOCK_DIM_X: 1024,\n",
              " pycuda._driver.device_attribute.MAX_BLOCK_DIM_Y: 1024,\n",
              " pycuda._driver.device_attribute.MAX_BLOCK_DIM_Z: 64,\n",
              " pycuda._driver.device_attribute.MAX_GRID_DIM_X: 2147483647,\n",
              " pycuda._driver.device_attribute.MAX_GRID_DIM_Y: 65535,\n",
              " pycuda._driver.device_attribute.MAX_GRID_DIM_Z: 65535,\n",
              " pycuda._driver.device_attribute.MAX_SHARED_MEMORY_PER_BLOCK: 49152,\n",
              " pycuda._driver.device_attribute.TOTAL_CONSTANT_MEMORY: 65536,\n",
              " pycuda._driver.device_attribute.WARP_SIZE: 32,\n",
              " pycuda._driver.device_attribute.MAX_PITCH: 2147483647,\n",
              " pycuda._driver.device_attribute.MAX_REGISTERS_PER_BLOCK: 65536,\n",
              " pycuda._driver.device_attribute.CLOCK_RATE: 1590000,\n",
              " pycuda._driver.device_attribute.TEXTURE_ALIGNMENT: 512,\n",
              " pycuda._driver.device_attribute.GPU_OVERLAP: 1,\n",
              " pycuda._driver.device_attribute.MULTIPROCESSOR_COUNT: 40,\n",
              " pycuda._driver.device_attribute.KERNEL_EXEC_TIMEOUT: 0,\n",
              " pycuda._driver.device_attribute.INTEGRATED: 0,\n",
              " pycuda._driver.device_attribute.CAN_MAP_HOST_MEMORY: 1,\n",
              " pycuda._driver.device_attribute.COMPUTE_MODE: pycuda._driver.compute_mode.DEFAULT,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_WIDTH: 131072,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_WIDTH: 131072,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_HEIGHT: 65536,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_WIDTH: 16384,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_HEIGHT: 16384,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_DEPTH: 16384,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_HEIGHT: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES: 2048,\n",
              " pycuda._driver.device_attribute.SURFACE_ALIGNMENT: 512,\n",
              " pycuda._driver.device_attribute.CONCURRENT_KERNELS: 1,\n",
              " pycuda._driver.device_attribute.ECC_ENABLED: 1,\n",
              " pycuda._driver.device_attribute.PCI_BUS_ID: 0,\n",
              " pycuda._driver.device_attribute.PCI_DEVICE_ID: 4,\n",
              " pycuda._driver.device_attribute.TCC_DRIVER: 0,\n",
              " pycuda._driver.device_attribute.MEMORY_CLOCK_RATE: 5001000,\n",
              " pycuda._driver.device_attribute.GLOBAL_MEMORY_BUS_WIDTH: 256,\n",
              " pycuda._driver.device_attribute.L2_CACHE_SIZE: 4194304,\n",
              " pycuda._driver.device_attribute.MAX_THREADS_PER_MULTIPROCESSOR: 1024,\n",
              " pycuda._driver.device_attribute.ASYNC_ENGINE_COUNT: 3,\n",
              " pycuda._driver.device_attribute.UNIFIED_ADDRESSING: 1,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LAYERED_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LAYERED_LAYERS: 2048,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_GATHER_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_GATHER_HEIGHT: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE: 8192,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE: 8192,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE: 32768,\n",
              " pycuda._driver.device_attribute.PCI_DOMAIN_ID: 0,\n",
              " pycuda._driver.device_attribute.TEXTURE_PITCH_ALIGNMENT: 32,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS: 2046,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_WIDTH: 131072,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_HEIGHT: 65536,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_WIDTH: 16384,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_HEIGHT: 16384,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_DEPTH: 16384,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_LAYERED_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_LAYERED_LAYERS: 2048,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_HEIGHT: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_LAYERS: 2048,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS: 2046,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LINEAR_WIDTH: 134217728,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_WIDTH: 131072,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_HEIGHT: 65000,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_PITCH: 2097120,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT: 32768,\n",
              " pycuda._driver.device_attribute.COMPUTE_CAPABILITY_MAJOR: 7,\n",
              " pycuda._driver.device_attribute.COMPUTE_CAPABILITY_MINOR: 5,\n",
              " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH: 32768,\n",
              " pycuda._driver.device_attribute.STREAM_PRIORITIES_SUPPORTED: 1,\n",
              " pycuda._driver.device_attribute.GLOBAL_L1_CACHE_SUPPORTED: 1,\n",
              " pycuda._driver.device_attribute.LOCAL_L1_CACHE_SUPPORTED: 1,\n",
              " pycuda._driver.device_attribute.MAX_SHARED_MEMORY_PER_MULTIPROCESSOR: 65536,\n",
              " pycuda._driver.device_attribute.MAX_REGISTERS_PER_MULTIPROCESSOR: 65536,\n",
              " pycuda._driver.device_attribute.MANAGED_MEMORY: 1,\n",
              " pycuda._driver.device_attribute.MULTI_GPU_BOARD: 0,\n",
              " pycuda._driver.device_attribute.MULTI_GPU_BOARD_GROUP_ID: 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMn3LLA9omFF"
      },
      "source": [
        "#define the kernel\n",
        "kernel_code_template = \"\"\"\n",
        "__global__ void MatrixMulKernel(float *a, float *b, float *c)\n",
        "{\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    // Pvalue is used to store the element of the matrix\n",
        "    // that is computed by the thread\n",
        "    float Pvalue = 0;\n",
        "\n",
        "    // Each thread loads one row of M and one column of N,\n",
        "    //   to produce one element of P.\n",
        "    for (int k = 0; k < %(MATRIX_SIZE)s; ++k) {\n",
        "        float Aelement = a[ty * %(MATRIX_SIZE)s + k];\n",
        "        float Belement = b[k * %(MATRIX_SIZE)s + tx];\n",
        "        Pvalue += Aelement * Belement;\n",
        "    }\n",
        "\n",
        "    // Write the matrix to device memory;\n",
        "    // each thread writes one element\n",
        "    c[ty * %(MATRIX_SIZE)s + tx] = Pvalue;\n",
        "}\n",
        "\"\"\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa7FHK5ioooS"
      },
      "source": [
        "# define the (square) matrix size\n",
        "#  note that we'll only use *one* block of threads here\n",
        "#  as a consequence this number (squared) can't exceed max_threads\n",
        "# -> use MyDevice.get_attributes() to get this information\n",
        "MATRIX_SIZE = 32\n",
        "\n",
        "# create two random square matrices\n",
        "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2gmDQrOo-G4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc6ec6f-4c08-472e-f1df-289db981b635"
      },
      "source": [
        "# compute reference on the CPU to verify GPU computation\n",
        "time_start=time.time()\n",
        "c_cpu = np.dot(a_cpu, b_cpu)\n",
        "time_end=time.time()\n",
        "timeCPU = time_end-time_start\n",
        "print('enlapsed time (CPU):',timeCPU,' seconds')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enlapsed time (CPU): 0.00013875961303710938  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcq4CMaL15ci",
        "outputId": "068dca87-2e63-437c-9905-a244bec76674"
      },
      "source": [
        "# transfer host (CPU) memory to device (GPU) memory\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "# create empty gpu array for the result (C = A * B)\n",
        "c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "# get the kernel code from the template\n",
        "# by specifying the constant MATRIX_SIZE\n",
        "kernel_code = kernel_code_template % {\n",
        "    'MATRIX_SIZE': MATRIX_SIZE\n",
        "    }\n",
        "\n",
        "# compile the kernel code\n",
        "mod = compiler.SourceModule(kernel_code)\n",
        "\n",
        "# get the kernel function from the compiled module\n",
        "matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "# call the kernel on the card\n",
        "time_start=time.time()\n",
        "\n",
        "matrixmul(\n",
        "    # inputs\n",
        "    a_gpu, b_gpu,\n",
        "    # output\n",
        "    c_gpu,\n",
        "    # (only one) block of MATRIX_SIZE x MATRIX_SIZE threads\n",
        "    block = (MATRIX_SIZE, MATRIX_SIZE, 1),\n",
        "    )\n",
        "\n",
        "time_end=time.time()\n",
        "timeGPU = time_end-time_start\n",
        "print('enlapsed time (GPU):',timeGPU,' seconds')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enlapsed time (GPU): 0.0001888275146484375  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo3fQ3Y-2e0Y",
        "outputId": "2fcba003-1420-41bb-c9f0-5e608a402a88"
      },
      "source": [
        "# print the results\n",
        "def display(verbose=False):\n",
        "\n",
        "  print(\"Taille matrices : \", MATRIX_SIZE)\n",
        "  #print Matrices\n",
        "  if verbose == True:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Matrix A (GPU):\")\n",
        "    print(a_gpu.get())\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Matrix B (GPU):\")\n",
        "    print(b_gpu.get())\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Matrix C (GPU):\")\n",
        "    print(c_gpu.get())\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "  #print difference\n",
        "  print(\"CPU-GPU difference:\")\n",
        "  norm = np.linalg.norm(c_cpu - c_gpu.get())\n",
        "  if norm != 0:\n",
        "    print(c_cpu - c_gpu.get())\n",
        "  else:\n",
        "    print(norm)\n",
        "\n",
        "  #print difference time\n",
        "  print()\n",
        "  print(\"Rapport de temps CPU/GPU : \", round(timeCPU/timeGPU,3))\n",
        "\n",
        "display()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taille matrices :  32\n",
            "CPU-GPU difference:\n",
            "0.0\n",
            "\n",
            "Rapport de temps CPU/GPU :  0.735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN_SC7E6qCnB"
      },
      "source": [
        "#QUESTION 1: Comprenez bien chaque partie du code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F8_NEIs3WSv"
      },
      "source": [
        "Done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haveBctQqC03"
      },
      "source": [
        "#QUESTION 2: Comparez le temps necessaire pour la multiplication en CPU et en GPU pour MATRIX_SIZE = 8, 16, 32. Qu'en pensez vous?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE5k_r1Q3Y6Z"
      },
      "source": [
        "Le calcul avec CPU est plus rapide. Cela vient sûrement du fait qu'avec des matrices de cette taille, on perd plus de temps à transférer les données d'une zone mémoire à une autre que le temps gagné avec la parallélisation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0C81XMeqC-P"
      },
      "source": [
        "#QUESTION 3: Par quelle methode simple pourriez vous rendre la parallelisation GPU competitive par rapport a la methode CPU (i.e. avec numpy)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztTf9jhy90TA"
      },
      "source": [
        "Aucune idée"
      ]
    }
  ]
}