{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UuEvlOXmM44Q"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#EXERCICE : ACCELERATION GPU D'UN CNN (basique) CODE EN PYTHON/NUMPY\n",
    "#\n",
    "# -> Le but de cet exercice est\n",
    "#    (1) de bien comprendre comment les parametres d'un reseau de neurones sont appris\n",
    "#     et en particulier comment fonctionne la backpropagation. L'implementation  python\n",
    "#    de differentes couches de CNN est donnee. Le CNN apprend alors a reconnaitre des 0\n",
    "#    et des 1 du jeu de donnees MNIST.\n",
    "#    (2) rendre le code le plus rapide possible en utilisant de l'acceleration GPU avec\n",
    "#    openCL ou bien CUDA.\n",
    "#\n",
    "#-> Une fois le code compris ... un seul objectif : l'accelerer avec du code GPU !\n",
    "#\n",
    "#-> Conseil : Si le temps est limite, focalisez vous sur l'amélioration de\n",
    "#             'conv_backward', avec au debut un code openCL ou CUDA qui recode\n",
    "#             l'algorithme sequentiel puis ensuite sa parallelisation. Il sera alors\n",
    "#             evident de mesurer l'impact de la parallelisation !\n",
    "#             Une alternative est de se focaliser sur 'dense_forward' qui permet\n",
    "#             de comparer du code bien optimise avec numpy contre du code GPU. Cette\n",
    "#             alternative est plus simple a coder mais les gains potentiels sont\n",
    "#             moindres.\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ri8Q9VsNpXWu",
    "outputId": "e4d3eea3-f59b-4bc3-f9df-8da17361f5ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycuda\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 18.1MB/s \n",
      "\u001b[?25hCollecting pytools>=2011.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 11.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
      "Collecting appdirs>=1.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
      "Collecting mako\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 12.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
      "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
      "Building wheels for collected packages: pycuda, pytools\n",
      "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=621085 sha256=e977124653bff0e27bebf3aad07411984aed9d91a89ce9c1d4c66c0b622524c9\n",
      "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
      "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=266ebc770d5fa2770c8671cb8cbd2df3bc9e0c5d1b14aa4c0bea18f00e931297\n",
      "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
      "Successfully built pycuda pytools\n",
      "Installing collected packages: appdirs, pytools, mako, pycuda\n",
      "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{pycuda._driver.device_attribute.MAX_THREADS_PER_BLOCK: 1024,\n",
       " pycuda._driver.device_attribute.MAX_BLOCK_DIM_X: 1024,\n",
       " pycuda._driver.device_attribute.MAX_BLOCK_DIM_Y: 1024,\n",
       " pycuda._driver.device_attribute.MAX_BLOCK_DIM_Z: 64,\n",
       " pycuda._driver.device_attribute.MAX_GRID_DIM_X: 2147483647,\n",
       " pycuda._driver.device_attribute.MAX_GRID_DIM_Y: 65535,\n",
       " pycuda._driver.device_attribute.MAX_GRID_DIM_Z: 65535,\n",
       " pycuda._driver.device_attribute.MAX_SHARED_MEMORY_PER_BLOCK: 49152,\n",
       " pycuda._driver.device_attribute.TOTAL_CONSTANT_MEMORY: 65536,\n",
       " pycuda._driver.device_attribute.WARP_SIZE: 32,\n",
       " pycuda._driver.device_attribute.MAX_PITCH: 2147483647,\n",
       " pycuda._driver.device_attribute.MAX_REGISTERS_PER_BLOCK: 65536,\n",
       " pycuda._driver.device_attribute.CLOCK_RATE: 1590000,\n",
       " pycuda._driver.device_attribute.TEXTURE_ALIGNMENT: 512,\n",
       " pycuda._driver.device_attribute.GPU_OVERLAP: 1,\n",
       " pycuda._driver.device_attribute.MULTIPROCESSOR_COUNT: 40,\n",
       " pycuda._driver.device_attribute.KERNEL_EXEC_TIMEOUT: 0,\n",
       " pycuda._driver.device_attribute.INTEGRATED: 0,\n",
       " pycuda._driver.device_attribute.CAN_MAP_HOST_MEMORY: 1,\n",
       " pycuda._driver.device_attribute.COMPUTE_MODE: pycuda._driver.compute_mode.DEFAULT,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_WIDTH: 131072,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_WIDTH: 131072,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_HEIGHT: 65536,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_WIDTH: 16384,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_HEIGHT: 16384,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_DEPTH: 16384,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_HEIGHT: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES: 2048,\n",
       " pycuda._driver.device_attribute.SURFACE_ALIGNMENT: 512,\n",
       " pycuda._driver.device_attribute.CONCURRENT_KERNELS: 1,\n",
       " pycuda._driver.device_attribute.ECC_ENABLED: 1,\n",
       " pycuda._driver.device_attribute.PCI_BUS_ID: 0,\n",
       " pycuda._driver.device_attribute.PCI_DEVICE_ID: 4,\n",
       " pycuda._driver.device_attribute.TCC_DRIVER: 0,\n",
       " pycuda._driver.device_attribute.MEMORY_CLOCK_RATE: 5001000,\n",
       " pycuda._driver.device_attribute.GLOBAL_MEMORY_BUS_WIDTH: 256,\n",
       " pycuda._driver.device_attribute.L2_CACHE_SIZE: 4194304,\n",
       " pycuda._driver.device_attribute.MAX_THREADS_PER_MULTIPROCESSOR: 1024,\n",
       " pycuda._driver.device_attribute.ASYNC_ENGINE_COUNT: 3,\n",
       " pycuda._driver.device_attribute.UNIFIED_ADDRESSING: 1,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LAYERED_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LAYERED_LAYERS: 2048,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_GATHER_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_GATHER_HEIGHT: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE: 8192,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE: 8192,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE: 32768,\n",
       " pycuda._driver.device_attribute.PCI_DOMAIN_ID: 0,\n",
       " pycuda._driver.device_attribute.TEXTURE_PITCH_ALIGNMENT: 32,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS: 2046,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_WIDTH: 131072,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_HEIGHT: 65536,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_WIDTH: 16384,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_HEIGHT: 16384,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_DEPTH: 16384,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_LAYERED_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_LAYERED_LAYERS: 2048,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_HEIGHT: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_LAYERS: 2048,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS: 2046,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LINEAR_WIDTH: 134217728,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_WIDTH: 131072,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_HEIGHT: 65000,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_PITCH: 2097120,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT: 32768,\n",
       " pycuda._driver.device_attribute.COMPUTE_CAPABILITY_MAJOR: 7,\n",
       " pycuda._driver.device_attribute.COMPUTE_CAPABILITY_MINOR: 5,\n",
       " pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH: 32768,\n",
       " pycuda._driver.device_attribute.STREAM_PRIORITIES_SUPPORTED: 1,\n",
       " pycuda._driver.device_attribute.GLOBAL_L1_CACHE_SUPPORTED: 1,\n",
       " pycuda._driver.device_attribute.LOCAL_L1_CACHE_SUPPORTED: 1,\n",
       " pycuda._driver.device_attribute.MAX_SHARED_MEMORY_PER_MULTIPROCESSOR: 65536,\n",
       " pycuda._driver.device_attribute.MAX_REGISTERS_PER_MULTIPROCESSOR: 65536,\n",
       " pycuda._driver.device_attribute.MANAGED_MEMORY: 1,\n",
       " pycuda._driver.device_attribute.MULTI_GPU_BOARD: 0,\n",
       " pycuda._driver.device_attribute.MULTI_GPU_BOARD_GROUP_ID: 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CUDA STUFFS\n",
    "\n",
    "!pip install pycuda\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "from pycuda import driver, compiler, gpuarray, tools \n",
    "import pycuda.autoinit\n",
    "\n",
    "\n",
    "MyDevice=pycuda.driver.Device(0)\n",
    "MyDevice.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "evLOb1WkNBuF"
   },
   "outputs": [],
   "source": [
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#                     convolutional layer\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "def init_convolution_filter(size):\n",
    "  \"\"\"\n",
    "  size must be a list of the shape [size_h,size_w]\n",
    "  \"\"\"\n",
    "  w=(0.5+np.random.randn(size[0],size[1]))/(size[0]*size[1])\n",
    "  return w\n",
    "\n",
    "\n",
    "def conv_forward(input, w):\n",
    "    \"\"\"\n",
    "    INSPIRED BY: https://gist.github.com/neodelphis\n",
    "    Remark: here stride=1 / no padding / image has only one layer / only one filter\n",
    "\n",
    "    A naive implementation of the forward pass for a convolutional layer.\n",
    "    The input consists of N observations, each of height H and\n",
    "    width W.\n",
    "    We convolve each input with a filter of height HH and width WW.\n",
    "    Input:\n",
    "    - input: Input data of shape (N, H, W)\n",
    "    - w: Filter weights of shape (HH, WW)\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - output: Output data, of shape (N, H', W') where H' and W' are given by H'=H and W'=W\n",
    "    - cache: (input, w)\n",
    "    \"\"\"\n",
    "\n",
    "    N, H, W = input.shape\n",
    "    HH, WW = w.shape\n",
    "\n",
    "    # dimensions de la sortie (tests sur la validité des choix necessaires ensuite / sinon padding)\n",
    "    H_ = H\n",
    "    W_ = W\n",
    "\n",
    "    output = np.zeros((N, H_, W_))\n",
    "\n",
    "    # Version sans vectorisation\n",
    "    for n in range(N):       # On parcourt toutes les images\n",
    "            for i in range(H_): # indices du résultat\n",
    "                for j in range(W_):\n",
    "                    for k in range(HH): # indices du filtre\n",
    "                        for l in range(WW):\n",
    "                          if i+k<H and j+l<W:   #test whether we're inside the image\n",
    "                                output[n,i,j] += input[n, i+k, j+l] * w[k, l]\n",
    "\n",
    "    cache = (input, w)\n",
    "    return output, cache\n",
    "\n",
    "\n",
    "\n",
    "def conv_backward(grad_output, cache):\n",
    "    \"\"\"\n",
    "    INSPIRED BY: https://gist.github.com/neodelphis\n",
    "    Remark: here stride=1 / no padding / image has only one layer / only one filter\n",
    "\n",
    "    A naive implementation of the backward pass for a convolutional layer.\n",
    "\n",
    "    Inputs:\n",
    "    - grad_output: Upstream derivatives. -> Gradient of the loss at the output of the layer\n",
    "    - cache: A tuple of (input, w) as in conv_forward_naive\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - grad_input: Gradient of the loss at the input of the layer wrt input\n",
    "    - grad_w: Gradient of the loss at the input of the layer wrt w\n",
    "    \"\"\"\n",
    "\n",
    "    # Récupération des variables\n",
    "    input, w = cache\n",
    "\n",
    "    # Initialisations\n",
    "    grad_input = np.zeros_like(input)\n",
    "    grad_w = np.zeros_like(w)\n",
    "\n",
    "    # Dimensions\n",
    "    N, H, W = input.shape\n",
    "    HH, WW = w.shape\n",
    "    _, H_, W_ = grad_output.shape   #H_ and W_ sould be equal to H and W\n",
    "\n",
    "    # Version sans vectorisation\n",
    "    for n in range(N):       # On parcourt toutes les images\n",
    "            for i in range(HH): # indices du résultat\n",
    "                for j in range(WW):\n",
    "                    for k in range(H_): # indices du filtre\n",
    "                        for l in range(W_):\n",
    "                          if i+k<H_ and j+l<W_:\n",
    "                                grad_w[i,j] += input[n, i+k, j+l] * grad_output[n, k, l]\n",
    "\n",
    "\n",
    "    # Version sans vectorisation\n",
    "    for n in range(N):       # On parcourt toutes les images\n",
    "            for i in range(H): # indices de l'entrée participant au résultat\n",
    "                for j in range(W):\n",
    "                    for k in range(HH): # indices du filtre\n",
    "                        for l in range(WW):\n",
    "                          if i+k<H and j+l<W:\n",
    "                                grad_input[n,i,j] += grad_output[n, i+k, j+l] * w[HH-k-1,WW-l-1]\n",
    "\n",
    "    return grad_input, grad_w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jt_S9cmjp7dh"
   },
   "outputs": [],
   "source": [
    "\n",
    "kernel_code_tpl = \"\"\"\n",
    "__global__ void cpt_grad_w_Kernel(float *input, float *grad_output, float *grad_w)\n",
    "{\n",
    "    int i = threadIdx.x;\n",
    "    int j = threadIdx.y;\n",
    "    float tmp=0.;\n",
    "    int k;\n",
    "    int l;\n",
    "\n",
    "    for (k=0;k<28-i;k++){\n",
    "      for (l=0;l<28-j;l++){\n",
    "        tmp+=input[(i+k)* 28 + (j+l)]*grad_output[k* 28 + l];\n",
    "      }\n",
    "    }\n",
    "    grad_w[j* 5 + i]+=tmp; \n",
    "}\n",
    "__global__ void cpt_grad_w_seq_Kernel(float *input, float *grad_output, float *grad_w)\n",
    "{\n",
    "    int bidon = threadIdx.x;\n",
    "    \n",
    "    float tmp;\n",
    "    int i;\n",
    "    int j;\n",
    "    int k;\n",
    "    int l;\n",
    "\n",
    "    for (i=0;i<5;i++){\n",
    "      for (j=0;j<5;j++){\n",
    "        tmp=0.;\n",
    "        for (k=0;k<28-i;k++){\n",
    "          for (l=0;l<28-j;l++){\n",
    "            tmp+=input[(i+k)* 28 + (j+l)]*grad_output[k* 28 + l];\n",
    "          }\n",
    "        }\n",
    "        grad_w[j* 5 + i]+=tmp;\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void cpt_grad_input_Kernel(float *grad_output, float *w, float *grad_input)\n",
    "{\n",
    "    int i = threadIdx.x;\n",
    "    int j = threadIdx.y;\n",
    "    float tmp=0.;\n",
    "    int k;\n",
    "    int l;\n",
    "\n",
    "    for (k=0;k<5;k++){\n",
    "      for (l=0;l<5;l++){\n",
    "        if ((i+k<28)&&(j+l<28)){\n",
    "          tmp+=grad_output[(i+k)* 28 + (j+l)] * w[(5-k-1 )* 5 + (5-l-1)];\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    grad_input[j* 28 + i]+=tmp;\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void cpt_grad_input_seq_Kernel(float *grad_output, float *w, float *grad_input)\n",
    "{\n",
    "    int bidon = threadIdx.x;\n",
    "    float tmp;\n",
    "    int i;\n",
    "    int j;\n",
    "    int k;\n",
    "    int l;\n",
    "\n",
    "    for (i=0;i<28;i++){\n",
    "      for (j=0;j<28;j++){\n",
    "        tmp=0.;\n",
    "        for (k=0;k<5;k++){\n",
    "          for (l=0;l<5;l++){\n",
    "            if ((i+k<28)&&(j+l<28)){\n",
    "              tmp+=grad_output[(i+k)* 28 + (j+l)] * w[(5-k-1 )* 5 + (5-l-1)];\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        grad_input[j* 28 + i]+=tmp;\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "kernel_code = kernel_code_tpl\n",
    "\n",
    "mod = compiler.SourceModule(kernel_code)\n",
    "cpt_grad_w_gpu = mod.get_function(\"cpt_grad_w_Kernel\")            #parallized version\n",
    "cpt_grad_input_gpu = mod.get_function(\"cpt_grad_input_Kernel\")  #parallized version\n",
    "\n",
    "cpt_grad_w_seq_gpu = mod.get_function(\"cpt_grad_w_seq_Kernel\")           #sequential version\n",
    "cpt_grad_input_seq_gpu = mod.get_function(\"cpt_grad_input_seq_Kernel\")   #sequential version\n",
    "\n",
    "\n",
    "def conv_backward_GPU(grad_output, cache):\n",
    "    \"\"\"\n",
    "    Same as conv_backward with GPU code \n",
    "    \"\"\"\n",
    "\n",
    "    # Récupération des variables\n",
    "    input, w = cache\n",
    "\n",
    "    # Initialisations\n",
    "    grad_input = np.zeros_like(input).astype(np.float32)\n",
    "    grad_w = np.zeros_like(w).astype(np.float32)\n",
    "\n",
    "    # Dimensions\n",
    "    N, H, W = input.shape\n",
    "    HH, WW = w.shape\n",
    "    _, H_, W_ = grad_output.shape   #H_ and W_ sould be equal to H and W\n",
    "\n",
    "    # Version GPU\n",
    "    w_gpu = gpuarray.to_gpu(w)\n",
    "\n",
    "    grad_w_gpu = gpuarray.to_gpu(grad_w)\n",
    "\n",
    "\n",
    "\n",
    "    for n in range(N):       # On parcourt toutes les images\n",
    "            \n",
    "      input_gpu = gpuarray.to_gpu(input[n,:,:].astype(np.float32))\n",
    "      grad_output_gpu = gpuarray.to_gpu(grad_output[n,:,:].astype(np.float32))\n",
    "      grad_input_gpu = gpuarray.to_gpu(grad_input[n,:,:])\n",
    "            \n",
    "      cpt_grad_w_gpu(input_gpu, grad_output_gpu, grad_w_gpu , block=(HH,WW,1)) #parallized version\n",
    "      cpt_grad_input_gpu(grad_output_gpu, w_gpu, grad_input_gpu, block=(H,W,1)) #parallized version\n",
    "      \n",
    "      #cpt_grad_w_seq_gpu(input_gpu, grad_output_gpu, grad_w_gpu , block=(1,1,1))     #sequential version\n",
    "      #cpt_grad_input_seq_gpu(grad_output_gpu, w_gpu, grad_input_gpu, block=(1,1,1))  #sequential version\n",
    "\n",
    "    grad_w=grad_w_gpu.get()\n",
    "    grad_input[n,:,:]=grad_input_gpu.get()\n",
    "    #cuda.memcpy_dtoh(grad_w, grad_w_gpu)\n",
    "    #cuda.memcpy_dtoh(grad_input[n,:,:], grad_input_gpu)\n",
    "\n",
    "    return grad_input, grad_w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6afVK58vNP-b"
   },
   "outputs": [],
   "source": [
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#                     dense layer\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "def init_dense_layer_weights(input_size, output_size):\n",
    "  \"\"\"\n",
    "  INSPIRED BY:  https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9\n",
    "\n",
    "  initialize the weights of a dense layer\n",
    "  \"\"\"\n",
    "  weights = np.random.normal(loc=0.0,scale = np.sqrt(2/(input_size+output_size)),\n",
    "                                        size = (input_size,output_size))\n",
    "  return weights\n",
    "\n",
    "def dense_forward(input,weights):\n",
    "  \"\"\"\n",
    "  INSPIRED BY:  https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9\n",
    "\n",
    "  forward phase of a dense layer\n",
    "  \"\"\"\n",
    "  cache = (input,weights)\n",
    "  output = np.dot(input,weights)\n",
    "\n",
    "  return output, cache\n",
    "\n",
    "def dense_backward(grad_output,cache):\n",
    "  \"\"\"\n",
    "  INSPIRED BY:  https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9\n",
    "\n",
    "  backward phase of a dense layer. The cache was returned by dense_forward.\n",
    "  \"\"\"\n",
    "  input,weights = cache\n",
    "\n",
    "  grad_input = np.dot(grad_output, weights.T)\n",
    "\n",
    "  grad_weights = np.dot(input.T, grad_output)\n",
    "\n",
    "  return grad_input , grad_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RboG9w4HNSuT"
   },
   "outputs": [],
   "source": [
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#                     ReLU layer\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "def ReLU_forward(input):\n",
    "  \"\"\"\n",
    "  INSPIRED BY:  https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9\n",
    "  \"\"\"\n",
    "\n",
    "  cache = (input)\n",
    "  output = np.maximum(0,input)\n",
    "  return output , cache\n",
    "\n",
    "def ReLU_backward(grad_output,cache):\n",
    "  \"\"\"\n",
    "  INSPIRED BY:  https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9\n",
    "  \"\"\"\n",
    "\n",
    "  input = cache\n",
    "  relu_grad = input > 0\n",
    "  grad_input=grad_output*relu_grad\n",
    "\n",
    "  return grad_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GqTyAQ4nNV9K"
   },
   "outputs": [],
   "source": [
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#                     logistic function\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "def Logistic_function(input):\n",
    "  return 1 / (1 + np.exp(-input))\n",
    "\n",
    "def derivative_Logistic_function(input):\n",
    "  lf_input=Logistic_function(input)\n",
    "  return lf_input*(1-lf_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIx692c7Newt",
    "outputId": "bbc6c95a-3a8f-4632-9a9b-56722ea166a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 28, 28)\n",
      "(2000, 1)\n",
      "(1000, 28, 28)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#                     MAIN\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "#1) INIT\n",
    "\n",
    "#get and treat data\n",
    "data=np.genfromtxt('./mnist_0_1.csv',delimiter=',')\n",
    "\n",
    "n_tot=data.shape[0]\n",
    "p=data.shape[1]\n",
    "\n",
    "y_train=data[:int(2.*n_tot/3.),0].reshape(-1,1)\n",
    "X_train=(data[:int(2.*n_tot/3.),1:]/(255.*p)).reshape(-1,28,28)\n",
    "\n",
    "y_test=data[int(2.*n_tot/3.):,0].reshape(-1,1)\n",
    "X_test=(data[int(2.*n_tot/3.):,1:]/(255.*p)).reshape(-1,28,28)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ShowMNISTObservation(X_data,y_data,obsNb=0):\n",
    "  plt.clf()\n",
    "  plt.imshow(X_data[obsNb,:].reshape((28,28)))\n",
    "  plt.title('Observation '+str(obsNb)+': Label '+str((y_data[obsNb,0])))\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#ShowMNISTObservation(X_train,y_train,0)\n",
    "#ShowMNISTObservation(X_train,y_train,1)\n",
    "#...\n",
    "#ShowMNISTObservation(X_test,y_train,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0t8Foh2xNxy8",
    "outputId": "5c236b71-abb9-4991-f4e8-c57ea1e44f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "0.2499943200358273\n",
      "0.23418587876412902\n",
      "0.22705890453843\n",
      "0.1944550206550416\n",
      "0.17593032795043528\n",
      "0.13782910609170096\n",
      "0.12646558656732065\n",
      "0.0872772200827034\n",
      "0.06878458295342642\n",
      "0.05919951593389326\n",
      "0.042453062008353824\n",
      "0.035423565803161264\n",
      "0.027622207152667878\n",
      "0.035432450615660735\n",
      "0.02969275088586318\n",
      "0.020466740283250115\n",
      "0.01830529643995694\n",
      "0.019450719698541126\n",
      "0.01659497791802978\n",
      "epoch: 1\n",
      "0.01658127277789156\n",
      "0.03323726777775547\n",
      "0.009555964731716908\n",
      "0.011561660675481714\n",
      "0.007361290795198185\n",
      "0.008405421034139578\n",
      "0.013105261017550994\n",
      "0.008332169899911231\n",
      "0.00780667947480719\n",
      "0.017971225089736566\n",
      "0.01519585914013818\n",
      "0.008578617303488155\n",
      "0.007157340890007351\n",
      "0.013202040542471179\n",
      "0.010093862151075626\n",
      "0.007028244376023068\n",
      "0.007277049962509503\n",
      "0.0054762689277355545\n",
      "0.007316551928472683\n",
      "Total time: 58.05203366279602\n",
      "Time in conv_backward: 1.2494361400604248\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#2) TRAINING\n",
    "#generate the network parameters\n",
    "w_conv=init_convolution_filter([5,5])\n",
    "w_dense=init_dense_layer_weights(28*28, 1)\n",
    "\n",
    "w_conv_init=w_conv.copy()\n",
    "w_dense_init=w_dense.copy()\n",
    "\n",
    "#Stochastic gradient Descent\n",
    "Batch_size=100\n",
    "nb_epochs=2\n",
    "\n",
    "n=X_train.shape[0]\n",
    "\n",
    "total_time_in_conv_backward=0.\n",
    "start_time= time()\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    print('epoch:',epoch)\n",
    "    obsIDs=np.arange(n)\n",
    "    np.random.shuffle(obsIDs)\n",
    "    batch_start=0\n",
    "\n",
    "    while batch_start+Batch_size<n:\n",
    "      x_batch=X_train[obsIDs[batch_start:batch_start+Batch_size],:,:]\n",
    "      y_true_batch=y_train[obsIDs[batch_start:batch_start+Batch_size],:]\n",
    "\n",
    "      #forward phase\n",
    "      output_1 , cache_1 = conv_forward(x_batch, w_conv)\n",
    "      output_2 , cache_2 = ReLU_forward(output_1)\n",
    "      output_3 , cache_3 = dense_forward(output_2.reshape(-1,28*28),w_dense) #the reshape is used to flatten the image\n",
    "      y_pred = Logistic_function(output_3)\n",
    "\n",
    "      MSE_loss = np.mean( np.power(y_pred-y_true_batch,2.) ) #log-likelihood would be slightly more general\n",
    "\n",
    "      #backward phase\n",
    "      grad_MSE_loss = 2*(y_pred-y_true_batch)\n",
    "      grad_output_3=grad_MSE_loss*derivative_Logistic_function(output_3)\n",
    "      grad_output_2 , grad_w_dense = dense_backward(grad_output_3,cache_3)\n",
    "      grad_output_1=ReLU_backward(grad_output_2.reshape(-1,28,28),cache_2)  #the reshape reverts the flattening\n",
    "      rtime = time()\n",
    "      grad_input, grad_w_conv=conv_backward_GPU(grad_output_1, cache_1)\n",
    "      rtime = time() - rtime\n",
    "      total_time_in_conv_backward+=rtime\n",
    "\n",
    "      #gradient descent-update\n",
    "      w_dense-=500*grad_w_dense\n",
    "      w_conv-=0.001*grad_w_conv    #REMARK: the learning rate has to be much smaller on the convolutional layer than on the dense layer (the data should be re-scaled in this layer to avoid this)\n",
    "\n",
    "      #prepare the next mini-batch\n",
    "      batch_start+=Batch_size\n",
    "\n",
    "      print(MSE_loss)\n",
    "\n",
    "print('Total time:',time() - start_time)\n",
    "print('Time in conv_backward:',total_time_in_conv_backward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "YZAzUE74ODZs",
    "outputId": "c66f1d7a-8ce7-41c2-f453-6d957bec4e28"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXIUlEQVR4nO3df7BcZX3H8fdn749w85OEHzEEBIroFBkLNmJbrdKxtYjOoLZF6dTGGW20o7WOdEZqO5VpdYaxVeuMrTYKAtYitGqhHUtB1EHGagkUEaWIStCkISGG/L7hZu9++8ee6BLueZ6bu7t3N3k+r5k7d+959pzz3XPv957d8z3P8ygiMLNjX2PQAZjZ/HCymxXCyW5WCCe7WSGc7GaFcLKbFcLJPkCS/kPS2j5s9wxJIWl0ls+/VtL7eh3HXA1bPMeKWf0x2M9I2tvx40LgSWC6+vktEfGZ2W4rIl7Ry9jMUpzsRygiFh96LGkj8OaI+NLhz5M0GhHN+YzN5q6E35ffxveIpAslbZL0bkmPAZ+StFzSv0t6XNIT1eNTO9b5qqQ3V4/fKOkuSX9TPfcRSa/oeO4ySVdL2iJps6T3SRqp2kaq9bZL+iHwykys50u6V9IeSTcCxx3W/ipJ90naKenrkp7X0bZR0p9Iul/SLkk3Sjquajuxeo07Je2Q9DVJjartFEmfq47FI5LeMcvjWnsMJf2OpHsOe/67JN1cPV5QHZcfSdoq6eOSJup+X7OJ52jmZO+tZwArgNOBdbSP76eqn58JTAIfTaz/QuAh4ETgA8DVklS1XQs0gWcB5wMvB95ctf0B8Kpq+Rrgt+t2IGkc+Ffg01Ws/wz8Vkf7+cA1wFuAE4B/AG6RtKBjM5cCFwFnAs8D3lgtvxzYBJwErATeA0SV8P8GfAtYDbwMeKek30wci0NSx/AW4ExJP9/x/DcA11ePrwKeDZxH+7itBv6i47mH/76ObRHhrzl+ARuBX68eXwhMAcclnn8e8ETHz1+l/TEA2gnz/Y62hUDQ/oNcSfvawERH+2XAV6rHXwbe2tH28mrd0RlieAnwf4A6ln0deF/1+GPAXx22zkPASzte8+91tH0A+Hj1+C+Bm4FnHbb+C4EfHbbsT4FP1Rynaw/FM4tj+DHg/dXj5wJPAAsAAfuAszqe+8vAI7P9fR1rX/7M3luPR8SBQz9IWgh8mPZZcHm1eImkkYiYnmH9xw49iIj91Ul9Me2zzxiw5WcnehrAj6vHp3Q8Bng0EeMpwOao/uJneP7pwFpJf9SxbLxa72lxAvs72v4auBK4rYpzfURcVW3zFEk7O9YbAb6WiBOY1TG8DrhB0p/TPqvfFBFPSjqZ9j/MezqOmar9HvKU39exzsneW4d3IbwceA7wwoh4TNJ5wP/Q/qM7Ej+mfWY/MWa+iLQFOK3j52cmtrUFWC1JHQn/TOAHHft6f0S8/whjJCL20H7Nl0s6F/iypLurbT4SEWcf6TbJHMOI+IakKeBXgd+tvgC2037L/9yI2FwX8hziOWr5M3t/LaH9B7dT0grgvXPZSERsAW4DPihpqaSGpLMkvbR6yk3AOySdKmk5cEVic/9F+7P/OySNSXotcEFH+yeAt0p6odoWSXqlpCW5OKsLe8+qrjPsol2SbAH/DeypLoZNVBcUz5X0glm8/Nkcw+tpf44/GBF3AUREq3otH67O8khaPcvrBMckJ3t//S0wQfss8w3g1i629fu0305/l/bn0n8BVlVtnwD+k/YFsHuBz9dtJCKmgNfSvkawA3hd5/MjYgPtC34frfbzfX52AS7nbOBLwF7a/1T+PiK+Ur3dfhXtz9uP0D4enwSWzWKbszmGnwbOBf7xsOXvruL/hqTdVWzPmeVrOeboqR/dzI4+VTltG/D8iHh40PEMK5/Z7Vjwh8DdTvQ0X6Czo5radzEKePWAQxl6fhtvVgi/jTcrxLy+jR+dWBTjS1fM5y6t37p5Y3ikdxtY1tTuHTQn9814ZLtKdkkXAR+hfVfSJ6u7pWqNL13B2a97Vze7LFJ0kRTq96e0PiZ7N6+7W30/bn3y8I0fqm2b89v4qsfV3wGvAM4BLpN0zly3Z2b91c1n9gtod9z4YXWjxmeBS3oTlpn1WjfJvpqndr7YVC17CknrJG2QtKE5ua+L3ZlZN/p+NT4i1kfEmohYMzqxqN+7M7Ma3ST7Zp7a0+rUapmZDaFukv1u4GxJZ1ajn7ye9sghZjaE5lx6i4impLfT7m01AlwTEd/pWWQF6WuJqZVuVuYOylAfg8uV3rr8kNlN+Sy36tFYmuuqzh4RXwS+2KNYzKyPfLusWSGc7GaFcLKbFcLJblYIJ7tZIZzsZoXwsFS9kKu5Ztq7rWSnauWaaSqKzvZMHT4amTp8F6eLXA0/V8vu6v6E3O/kKKyj5/jMblYIJ7tZIZzsZoVwspsVwsluVggnu1khiim95co02VJLokTVmE6vnCt/dT1xcOK1NWaa4PkI9p0trXUxQmy00jtvZTaerbwNcpjrIRwm22d2s0I42c0K4WQ3K4ST3awQTnazQjjZzQrhZDcrRDF19lxXTmVqvql6deNgetsjU5k6fCa21kimfbSbaV4zzV3cfwDQSLRH5nUpc/9CVqrGnznN5dtzBy7dPAg+s5sVwsluVggnu1khnOxmhXCymxXCyW5WCCe7WSEKqrPPvY4O0Jiqbxs9kN722P50MToXW/O49P/k5kRq3XTBt5X7C8jUi0cOZNoT9xg0nszsOzOddO4egOmx+uCnxzPHZSy97dZol1NdD6AO31WyS9oI7AGmgWZErOlFUGbWe704s/9aRGzvwXbMrI/8md2sEN0mewC3SbpH0rqZniBpnaQNkjY0J/d1uTszm6tu38a/OCI2SzoZuF3S/0bEnZ1PiIj1wHqAhStPOwZn0DI7OnR1Zo+IzdX3bcAXgAt6EZSZ9d6ck13SIklLDj0GXg480KvAzKy3unkbvxL4gtr1xFHgnyLi1p5EVSfxISBXq86N3Z7rk56qpY/vSW98bE+miJ+pJ4fGk+1PLq3/nz21NF3QbS5MNmeN7063jz5Z/9rG9qaP2+hkbsD9tObC+g7zU4vTnembmTp5t/3hj6o6e0T8EPiFHsZiZn3k0ptZIZzsZoVwspsVwsluVggnu1khjq4ursnSW3rV7HDPiRIRwNi++h2M70z0fwVGdmf6co6m/+dOLU+X3lLltcmVme6zy7orb8Vj6T+hBTvrYxvbly5Jjm3fn953pjym5fV9f1uJ7q/t9vTvJLe+h5I2s4FxspsVwsluVggnu1khnOxmhXCymxXCyW5WiOGqs2fGsUl1Y1WmF+nIwUwdfTJdqB/fU1+oH92VHk9ZezP14sXpfqYHF6b/Jx84qf61tVanY3vGCek+qs3pdFfQnxxcnmxv/ag+9pG96fsT9JOd6fbR9J/vyIL62BuL0+sqMTw3kJ2qOve3PIg6vM/sZoVwspsVwsluVggnu1khnOxmhXCymxXCyW5WiKOqzt5IdL0e6bK/+mhmWuWR3fU1Ye3am1w3JifT7UsWJdufPD5dlJ1aWX+TwbNXPZ5c9xdX/CjZvjMz1vSt25ck24n6vviNvel+/q3de5LtGk/Pq9xYWn9cGwdz02in7y/ITRet3PDgAyi0+8xuVggnu1khnOxmhXCymxXCyW5WCCe7WSGc7GaFmN86e5Ae+z1Tm0xNu9xoZuroiSmXAUb3pgv1I7v21ba1dmXmLZ5Oj83eWpweF37y5HRN9sRVu2rbXnrSw8l1f2VRuv2+A89Mtt/aOCfZPjaZGINgX/r+g+nM/QmN3LjxzfrjnptnIFdHPxplz+ySrpG0TdIDHctWSLpd0sPV9/QIBmY2cLN5G38tcNFhy64A7oiIs4E7qp/NbIhlkz0i7gR2HLb4EuC66vF1wKt7HJeZ9dhcL9CtjIgt1ePHgJV1T5S0TtIGSRuak/Wfe82sv7q+Gh8RyctuEbE+ItZExJrRiXSHDzPrn7km+1ZJqwCq79t6F5KZ9cNck/0WYG31eC1wc2/CMbN+ydbZJd0AXAicKGkT8F7gKuAmSW8CHgUundXeRHK87Owc64mx4Uemcv3V07Xu3BzqsSdRZ9+XHhe+sSjdJ/zAicel25+Rjv1FJ22ubXvp4geT654zlh5X/ntT6bHdY39ufvb62GNvehwAMvdd0MicqzJ1+K72PYwTsGdkkz0iLqtpelmPYzGzPvLtsmaFcLKbFcLJblYIJ7tZIZzsZoUYri6uuW6H0/UrNzJTMo9Mpud0bmS6W7b2JW71baVLY41lS5Pt+1amhy0ePyldonrB0kdq284dT5cUF2pBsn3zVLpD4/jj6dgXbK8fDro1mS775UpnGsmcq0YTseUqZ5l9R2b96Kbs1yc+s5sVwsluVggnu1khnOxmhXCymxXCyW5WCCe7WSHmf8rmVDk818U1NWVzZkrmRqbOHvszdfYD9fVqjaWHgp5eeXyyPTdU9OoV9UNFAzx3wabatmWNieS6W5rpGv7dO05Pti/cko595Cf1dfbmwfTvRCPpGj4L0vcIxFj9+q2x9HkucqfB4SujZ/nMblYIJ7tZIZzsZoVwspsVwsluVggnu1khnOxmhZj/OntCbprcVH/3xlS6SN84kB4SmSfT/b6T2z5+WbJ9/8npoaSnjk+/8NWLdibbF6l+uum9rfS2v3ZgdbL9oU21M3sBcMqWdF/+2JOo40f6d6bx9D0CmkgPwd2cGKtta42lC+WtTIk/3x8+0z4APrObFcLJblYIJ7tZIZzsZoVwspsVwsluVggnu1kh5r3OrtRUuNk6e2Lc+OlMZ/hmph6c6VvdOC7Rd3p5elz4J5eni7bTi9OxLx5N3yOws1Vfj96QuX3glu3nJ9tHH03Xsie2pccBYKr+HgCN1tfBAbRoUbK9tTR9/8L0wvo/7+kFmTr7aJd1+CGUPbNLukbSNkkPdCy7UtJmSfdVXxf3N0wz69Zs3sZfC1w0w/IPR8R51dcXexuWmfVaNtkj4k5gxzzEYmZ91M0FurdLur96m187IZikdZI2SNrQnEzMl2ZmfTXXZP8YcBZwHrAF+GDdEyNifUSsiYg1oxPpCy5m1j9zSvaI2BoR0xHRAj4BXNDbsMys1+aU7JJWdfz4GuCBuuea2XDI1tkl3QBcCJwoaRPwXuBCSefRroxvBN4y2x2m563OFNq7karvAxrLHIrE2PCtZel678GJzFzfI+k6+46p9Pbvnjyztu3HB1Yk1/3GxjOS7Uvrh6QHYGRvppCfGPu9sXRxet3M/QvNpel7AA4urt93M1dnT98CcFT2Z88me0RcNsPiq/sQi5n1kW+XNSuEk92sEE52s0I42c0K4WQ3K8RQDSWdmya3NVJfz2iNZFYe7647JQvqS2/Tx2UOY6YM0ziQjv2h7Scn27fuX1Lb9tjOdPlq5JH0cM0TO7orhypRXovEMQVonpAuzR1clv6dNifqj+v0eK4cmmwmGkNYW8vwmd2sEE52s0I42c0K4WQ3K4ST3awQTnazQjjZzQoxXHX2TG0z1e1wOlFTBZhenBgKGsiNDByj9duPzLDDI5nZosefSMe+ayw9JfTOkfpa+uiu9CtbtDUXe3oI7lZiWmQAVH8PwPSidJ196vj0tqeWpF9b87jEfRnpXWeHks7dOxG51fvYm7uOz+xmhXCymxXCyW5WCCe7WSGc7GaFcLKbFcLJblaI+a+zJ+qPuf7sqT7IU4lhgwFopYcdHpvIHIrEaM+tsXTgowfSRdUFO9JF2cbB9GtL3Z8wkhnpeXQyHVtqDAGAqWXpgrWW1rc3F6aP28FMe3Y46ERoudd1NNbRc3xmNyuEk92sEE52s0I42c0K4WQ3K4ST3awQTnazQsxmyubTgOuBlbTnVF4fER+RtAK4ETiD9rTNl0bEE+mNkamzp4uX0+P1xcv0VNDQGkvXqg9m+kY3DtbvW61MUTUzXfTYvsx00pmibisReqOZXDV5/wDAdKaWHY3MPQCJ32lu7PbpTJ/zyN0akaqlF3iam81LbgKXR8Q5wC8Bb5N0DnAFcEdEnA3cUf1sZkMqm+wRsSUi7q0e7wEeBFYDlwDXVU+7Dnh1v4I0s+4d0ZsZSWcA5wPfBFZGxJaq6THab/PNbEjNOtklLQY+B7wzInZ3tkVE0P48P9N66yRtkLShObmvq2DNbO5mleySxmgn+mci4vPV4q2SVlXtq4BtM60bEesjYk1ErBmdyEyeaGZ9k012SQKuBh6MiA91NN0CrK0erwVu7n14ZtYrs+ni+iLgDcC3Jd1XLXsPcBVwk6Q3AY8Cl3YdTa5bYaKUMp35t5Ur0zTTPWBpNOv3rfRoyyhTelOm/DWS6Yaamq061xUz9+/+4ER6A8qW5ua+71RJsb3t7rqpdmMYu7DmZJM9Iu6i/rC9rLfhmFm/FHhrgVmZnOxmhXCymxXCyW5WCCe7WSGc7GaFGKopm7uqi2bWbWW6wObmbG6NJQqrmZqrWpladabOnmsnUefPdgPNtGdr2bnXnrjHINctOfv30Mc6+rHIZ3azQjjZzQrhZDcrhJPdrBBOdrNCONnNCuFkNyvEcNXZ+ylXLs71h09sINe3OdOdHU3nhpJOr5/SGpv7MNSzkb0HINuh3uaLz+xmhXCymxXCyW5WCCe7WSGc7GaFcLKbFcLJblaIcursfZQtJWfbM2OvH1E0h62b6zKeq5NndHMPQDa2o3Bs9mHmM7tZIZzsZoVwspsVwsluVggnu1khnOxmhXCymxUim+ySTpP0FUnflfQdSX9cLb9S0mZJ91VfF/c/3C5E+ksD/OqnYY59kMelRLO5qaYJXB4R90paAtwj6faq7cMR8Tf9C8/MeiWb7BGxBdhSPd4j6UFgdb8DM7PeOqLP7JLOAM4Hvlkteruk+yVdI2l5zTrrJG2QtKE5ua+rYM1s7mad7JIWA58D3hkRu4GPAWcB59E+839wpvUiYn1ErImINaMTi3oQspnNxaySXdIY7UT/TER8HiAitkbEdES0gE8AF/QvTDPr1myuxgu4GngwIj7UsXxVx9NeAzzQ+/DMrFdmczX+RcAbgG9Luq9a9h7gMknn0S5ebQTe0pcIe8UjGlvhZnM1/i5mTpUv9j4cM+sX30FnVggnu1khnOxmhXCymxXCyW5WCCe7WSGc7GaFcLKbFcLJblYIJ7tZIZzsZoVwspsVwsluVggnu1khFDF/Y/ZKehx4tGPRicD2eQvgyAxrbMMaFzi2ueplbKdHxEkzNcxrsj9t59KGiFgzsAAShjW2YY0LHNtczVdsfhtvVggnu1khBp3s6we8/5RhjW1Y4wLHNlfzEttAP7Ob2fwZ9JndzOaJk92sEANJdkkXSXpI0vclXTGIGOpI2ijp29U01BsGHMs1krZJeqBj2QpJt0t6uPo+4xx7A4ptKKbxTkwzPtBjN+jpz+f9M7ukEeB7wG8Am4C7gcsi4rvzGkgNSRuBNREx8BswJL0E2AtcHxHnVss+AOyIiKuqf5TLI+LdQxLblcDeQU/jXc1WtKpzmnHg1cAbGeCxS8R1KfNw3AZxZr8A+H5E/DAipoDPApcMII6hFxF3AjsOW3wJcF31+Drafyzzria2oRARWyLi3urxHuDQNOMDPXaJuObFIJJ9NfDjjp83MVzzvQdwm6R7JK0bdDAzWBkRW6rHjwErBxnMDLLTeM+nw6YZH5pjN5fpz7vlC3RP9+KIeD7wCuBt1dvVoRTtz2DDVDud1TTe82WGacZ/apDHbq7Tn3drEMm+GTit4+dTq2VDISI2V9+3AV9g+Kai3npoBt3q+7YBx/NTwzSN90zTjDMEx26Q058PItnvBs6WdKakceD1wC0DiONpJC2qLpwgaRHwcoZvKupbgLXV47XAzQOM5SmGZRrvumnGGfCxG/j05xEx71/AxbSvyP8A+LNBxFAT188B36q+vjPo2IAbaL+tO0j72sabgBOAO4CHgS8BK4Yotk8D3wbup51YqwYU24tpv0W/H7iv+rp40McuEde8HDffLmtWCF+gMyuEk92sEE52s0I42c0K4WQ3K4ST3awQTnazQvw/md9k1uletnAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial convolution filter:\n",
      " [[-0.02273159  0.10871395  0.04852223  0.00701996 -0.00116895]\n",
      " [ 0.02643704  0.06256419 -0.00531739 -0.04753842 -0.01567197]\n",
      " [ 0.01455576 -0.00567813  0.06549621  0.00756833  0.10406421]\n",
      " [ 0.03018358  0.00247295 -0.05895859  0.0936784   0.07112024]\n",
      " [ 0.07442261 -0.00549804 -0.00430565  0.03908149 -0.00604087]]\n",
      "Trained convolution filter:\n",
      " [[0.01743605 0.16539711 0.11983128 0.08850567 0.08485553]\n",
      " [0.1116793  0.16340819 0.10546907 0.06626086 0.09407391]\n",
      " [0.12501003 0.11443922 0.18816987 0.12522031 0.20985887]\n",
      " [0.13768675 0.11179591 0.04539873 0.18652348 0.14732518]\n",
      " [0.15250721 0.06696026 0.05754672 0.08622854 0.02423194]]\n",
      "Percentage of good predictions: 99.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#3) TEST\n",
    "\n",
    "#show the trained information\n",
    "\n",
    "plt.imshow(w_dense_init.reshape((28,28)))\n",
    "plt.title('initial dense layer')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(w_dense.reshape((28,28)))\n",
    "plt.title('Trained dense layer')\n",
    "plt.show()\n",
    "\n",
    "print('Initial convolution filter:\\n',w_conv_init)\n",
    "print('Trained convolution filter:\\n',w_conv)\n",
    "\n",
    "\n",
    "#predictions on test data\n",
    "\n",
    "output_1 , cache_1 = conv_forward(X_test, w_conv)\n",
    "output_2 , cache_2 = ReLU_forward(output_1)\n",
    "output_3 , cache_3 = dense_forward(output_2.reshape(-1,28*28),w_dense)\n",
    "y_pred = Logistic_function(output_3)\n",
    "\n",
    "MSE_loss = np.mean( np.power(y_pred-y_test,2.) )\n",
    "\n",
    "Nb_false_pred=np.sum(np.abs(1*(y_pred>0.5)-y_test))\n",
    "\n",
    "prct_false_pred=100.*Nb_false_pred/y_test.shape[0]\n",
    "\n",
    "print('Percentage of good predictions:',100-prct_false_pred)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_from_scratch_CUDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
